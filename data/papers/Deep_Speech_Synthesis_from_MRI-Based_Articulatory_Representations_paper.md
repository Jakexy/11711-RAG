Faculty: Shinji Watanabe
Title: Deep Speech Synthesis from MRI-Based Articulatory Representations
Abstract: In this paper, we study articulatory synthesis, a speech synthesis method using human vocal tract information that offers a way to develop efficient, generalizable and interpretable synthesizers. While recent advances have enabled intelligible articulatory synthesis using electromagnetic articulography (EMA), these methods lack critical articulatory information like excitation and nasality, limiting generalization capabilities. To bridge this gap, we propose an alternative MRI-based feature set that covers a much more extensive articulatory space than EMA. We also introduce normalization and denoising procedures to enhance the generalizability of deep learning methods trained on MRI data. Moreover, we propose an MRI-to-speech model that improves both computational efficiency and speech fidelity. Finally, through a series of ablations, we show that the proposed MRI representation is more comprehensive than EMA and identify the most suitable MRI feature subset for articulatory synthesis.
Year: 2023
Authors: Peter Wu, Tingle Li, Yijingxiu Lu, Yubin Zhang, Jiachen Lian, A. Black, L. Goldstein, Shinji Watanabe, G. Anumanchipalli
Publication ID: af90489e-312f-4514-bea2-bcb399cb8ece
Publication Name: Interspeech
Publication Type: conference
Publication Alternate Names: Conf Int Speech Commun Assoc, INTERSPEECH, Conference of the International Speech Communication Association
Publication Issn: 2308-457X
Publication Url: https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech
Publication Alternate Urls: http://www.isca-speech.org/
