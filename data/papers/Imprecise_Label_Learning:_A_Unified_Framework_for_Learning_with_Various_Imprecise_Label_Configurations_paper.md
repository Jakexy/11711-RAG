The paper title is Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations.
The faculty author of the paper Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations is Rita Singh.
The paper Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations publication year is 2023.
Co-authors of the paper Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations are Hao Chen, Ankit Shah, Jindong Wang, R. Tao, Yidong Wang, Xingxu Xie, Masashi Sugiyama, Rita Singh, B. Raj.
The publication ID of the paper Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations is 1901e811-ee72-4b20-8f7e-de08cd395a10.
The publication name of the paper Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations is arXiv.org.
Publication alternate names of the paper Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations are ArXiv.
The publication issn of the paper Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations is 2331-8422.
The publication url of the paper Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations is https://arxiv.org.
The paper abstract is Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.
