The paper title is ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit.
The faculty author of the paper ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit is Shinji Watanabe.
The paper ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit publication year is 2023.
Co-authors of the paper ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit are Brian Yan, Jiatong Shi, Yun Tang, H. Inaguma, Yifan Peng, Siddharth Dalmia, Peter Pol'ak, Patrick Fernandes, Dan Berrebbi, Tomoki Hayashi, Xiaohui Zhang, Zhaoheng Ni, Moto Hira, Soumi Maiti, J. Pino, Shinji Watanabe.
The publication ID of the paper ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit is 1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44.
The publication name of the paper ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit is Annual Meeting of the Association for Computational Linguistics.
The publication type of the paper ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit is conference.
Publication alternate names of the paper ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit are Annu Meet Assoc Comput Linguistics, Meeting of the Association for Computational Linguistics, ACL, Meet Assoc Comput Linguistics.
The publication url of the paper ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit is https://www.aclweb.org/anthology/venues/acl/.
The paper abstract is ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) â€“ each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at https://github.com/espnet/espnet.
