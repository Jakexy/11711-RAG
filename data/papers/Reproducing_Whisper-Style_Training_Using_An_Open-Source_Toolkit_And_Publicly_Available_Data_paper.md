The paper title is Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data.
The faculty author of the paper Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data is Shinji Watanabe.
The paper Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data publication year is 2023.
Co-authors of the paper Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data are Yifan Peng, Jinchuan Tian, Brian Yan, Dan Berrebbi, Xuankai Chang, Xinjian Li, Jiatong Shi, Siddhant Arora, William Chen, Roshan Sharma, Wangyou Zhang, Yui Sudo, Muhammad Shakeel, Jee-weon Jung, Soumi Maiti, Shinji Watanabe.
The publication ID of the paper Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data is 29014a7c-861f-43bd-b4d6-63edf4cd57ef.
The publication name of the paper Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data is Automatic Speech Recognition & Understanding.
The publication type of the paper Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data is conference.
Publication alternate names of the paper Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data are IEEE Automatic Speech Recognition and Understanding Workshop, Autom Speech Recognit  Underst, ASRU, IEEE Autom Speech Recognit Underst Workshop.
The paper abstract is Pre-training speech models on large volumes of data has achieved remarkable success. OpenAI Whisper is a multilingual multitask model trained on 680k hours of supervised speech data. It generalizes well to various speech recognition and translation benchmarks even in a zero-shot setup. However, the full pipeline for developing such models (from data collection to training) is not publicly accessible, which makes it difficult for researchers to further improve its performance and address training-related issues such as efficiency, robustness, fairness, and bias. This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisperstyle training using an open-source toolkit and publicly available data. OWSM even supports more translation directions and can be more efficient to train. We will publicly release all scripts used for data preparation, training, inference, and scoring as well as pretrained models and training logs to promote open science. 11https://github.com/espnet/espnet
