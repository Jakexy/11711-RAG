The paper title is Factorized Contrastive Learning: Going Beyond Multi-view Redundancy.
The faculty author of the paper Factorized Contrastive Learning: Going Beyond Multi-view Redundancy is Louis-Philippe Morency.
The paper Factorized Contrastive Learning: Going Beyond Multi-view Redundancy publication year is 2023.
Co-authors of the paper Factorized Contrastive Learning: Going Beyond Multi-view Redundancy are P. Liang, Zihao Deng, Martin Q. Ma, James Y. Zou, Louis-Philippe Morency, R. Salakhutdinov.
The publication ID of the paper Factorized Contrastive Learning: Going Beyond Multi-view Redundancy is d9720b90-d60b-48bc-9df8-87a30b9a60dd.
The publication name of the paper Factorized Contrastive Learning: Going Beyond Multi-view Redundancy is Neural Information Processing Systems.
The publication type of the paper Factorized Contrastive Learning: Going Beyond Multi-view Redundancy is conference.
Publication alternate names of the paper Factorized Contrastive Learning: Going Beyond Multi-view Redundancy are Neural Inf Process Syst, NeurIPS, NIPS.
The publication url of the paper Factorized Contrastive Learning: Going Beyond Multi-view Redundancy is http://neurips.cc/.
The paper abstract is In a wide range of multimodal tasks, contrastive learning has become a particularly appealing approach since it can successfully learn representations from abundant unlabeled data with only pairing information (e.g., image-caption or video-audio pairs). Underpinning these approaches is the assumption of multi-view redundancy - that shared information between modalities is necessary and sufficient for downstream tasks. However, in many real-world settings, task-relevant information is also contained in modality-unique regions: information that is only present in one modality but still relevant to the task. How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy. FactorCL is built from three new contributions: (1) factorizing task-relevant information into shared and unique representations, (2) capturing task-relevant information via maximizing MI lower bounds and removing task-irrelevant information via minimizing MI upper bounds, and (3) multimodal data augmentations to approximate task relevance without labels. On large-scale real-world datasets, FactorCL captures both shared and unique information and achieves state-of-the-art results on six benchmarks
