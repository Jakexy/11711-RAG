The paper title is Program-Aided Reasoners (better) Know What They Know.
The faculty author of the paper Program-Aided Reasoners (better) Know What They Know is Graham Neubig.
The paper Program-Aided Reasoners (better) Know What They Know publication year is 2023.
Co-authors of the paper Program-Aided Reasoners (better) Know What They Know are Anubha Kabra, Sanketh Rangreji, Yash Mathur, Aman Madaan, Emmy Liu, Graham Neubig.
The publication ID of the paper Program-Aided Reasoners (better) Know What They Know is 1901e811-ee72-4b20-8f7e-de08cd395a10.
The publication name of the paper Program-Aided Reasoners (better) Know What They Know is arXiv.org.
Publication alternate names of the paper Program-Aided Reasoners (better) Know What They Know are ArXiv.
The publication issn of the paper Program-Aided Reasoners (better) Know What They Know is 2331-8422.
The publication url of the paper Program-Aided Reasoners (better) Know What They Know is https://arxiv.org.
The paper abstract is Prior work shows that program-aided reasoning, in which large language models (LLMs) are combined with programs written in programming languages such as Python, can significantly improve accuracy on various reasoning tasks. However, while accuracy is essential, it is also important for such reasoners to"know what they know", which can be quantified through the calibration of the model. In this paper, we compare the calibration of Program Aided Language Models (PAL) and text-based Chain-of-thought (COT) prompting techniques over 5 datasets and 2 model types: LLaMA models and OpenAI models. Our results indicate that PAL leads to improved calibration in 75% of the instances. Our analysis uncovers that prompting styles that produce lesser diversity in generations also have more calibrated results, and thus we also experiment with inducing lower generation diversity using temperature scaling and find that for certain temperatures, PAL is not only more accurate but is also more calibrated than COT. Overall, we demonstrate that, in the majority of cases, program-aided reasoners better know what they know than text-based counterparts.
