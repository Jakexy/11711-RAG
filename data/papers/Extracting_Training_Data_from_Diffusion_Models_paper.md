The paper title is Extracting Training Data from Diffusion Models.
The faculty author of the paper Extracting Training Data from Diffusion Models is Daphne Ippolito.
The paper Extracting Training Data from Diffusion Models publication year is 2023.
Co-authors of the paper Extracting Training Data from Diffusion Models are Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tram√®r, B. Balle, Daphne Ippolito, Eric Wallace.
The publication ID of the paper Extracting Training Data from Diffusion Models is 54649c1d-6bcc-4232-9cd1-aa446867b8d0.
The publication name of the paper Extracting Training Data from Diffusion Models is USENIX Security Symposium.
The publication type of the paper Extracting Training Data from Diffusion Models is conference.
Publication alternate names of the paper Extracting Training Data from Diffusion Models are USENIX Secur Symp.
The publication url of the paper Extracting Training Data from Diffusion Models is http://www.usenix.org/events/bytopic/security.html.
The paper abstract is Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.
