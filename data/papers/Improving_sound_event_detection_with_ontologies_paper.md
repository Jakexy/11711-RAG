Faculty: Bhiksha Raj
Title: Improving sound event detection with ontologies
Abstract: Sound event recognition is the task of identifying and categorizing sounds in audio data. Automated algorithms for sound event recognition depend on having explicit models for individual sound event types to be recognized, which are trained on data tagged explicitly for those classes. The approach is data hungryand is fundamentally limited by the number of classes for which such data may be obtained. It also ignores the relationship between sounds being modeled. In this work, we attempt to address these deficiencies through the use of a human-generated sound ontology which represents sibling and parent–child relations between sound classes. We incorporate the relationships in the ontology through the design of an appropriate “loss” function (the objective function optimized to train sound-classifier models) that incorporates the relationships in the ontology, and through appropriate model update rules which utilize data from a class to update parameters (of both ontological siblings and parents). Through experiments run on the “Audioset” (a popular, large-scale dataset of 600 sound categories), we find that better-performing models can be trained for sound classes with a given dataset, and that the amount of new data required to train models for a novel sound class can be significantly reduced.
Year: 2023
Authors: B. Raj
Publication ID: cc124a8d-f3a0-44cc-85b4-6a1a6ffdd673
Publication Name: Journal of the Acoustical Society of America
Publication Type: journal
Publication Alternate Names: J Acoust Soc Am
Publication Issn: 0001-4966
Publication Url: http://scitation.aip.org/content/asa/journal/jasa
Publication Alternate Urls: https://asa.scitation.org/journal/jas, https://asa.scitation.org/toc/jas/current
