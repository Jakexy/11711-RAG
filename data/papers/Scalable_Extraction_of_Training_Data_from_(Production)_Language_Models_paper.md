The paper title is Scalable Extraction of Training Data from (Production) Language Models.
The faculty author of the paper Scalable Extraction of Training Data from (Production) Language Models is Daphne Ippolito.
The paper Scalable Extraction of Training Data from (Production) Language Models publication year is 2023.
Co-authors of the paper Scalable Extraction of Training Data from (Production) Language Models are Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. F. Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tram√®r, Katherine Lee.
The publication ID of the paper Scalable Extraction of Training Data from (Production) Language Models is 1901e811-ee72-4b20-8f7e-de08cd395a10.
The publication name of the paper Scalable Extraction of Training Data from (Production) Language Models is arXiv.org.
Publication alternate names of the paper Scalable Extraction of Training Data from (Production) Language Models are ArXiv.
The publication issn of the paper Scalable Extraction of Training Data from (Production) Language Models is 2331-8422.
The publication url of the paper Scalable Extraction of Training Data from (Production) Language Models is https://arxiv.org.
The paper abstract is This paper studies extractable memorization: training data that an adversary can efficiently extract by querying a machine learning model without prior knowledge of the training dataset. We show an adversary can extract gigabytes of training data from open-source language models like Pythia or GPT-Neo, semi-open models like LLaMA or Falcon, and closed models like ChatGPT. Existing techniques from the literature suffice to attack unaligned models; in order to attack the aligned ChatGPT, we develop a new divergence attack that causes the model to diverge from its chatbot-style generations and emit training data at a rate 150x higher than when behaving properly. Our methods show practical attacks can recover far more data than previously thought, and reveal that current alignment techniques do not eliminate memorization.
