The paper title is Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints.
The faculty author of the paper Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints is Emma Strubell.
The paper Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints publication year is 2023.
Co-authors of the paper Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints are Rajshekhar Das, Jonathan M Francis, Sanket Vaibhav Mehta, Jean Oh, Emma Strubell, Jose Moura.
The publication ID of the paper Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints is 1901e811-ee72-4b20-8f7e-de08cd395a10.
The publication name of the paper Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints is arXiv.org.
Publication alternate names of the paper Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints are ArXiv.
The publication issn of the paper Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints is 2331-8422.
The publication url of the paper Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints is https://arxiv.org.
The paper abstract is Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.
