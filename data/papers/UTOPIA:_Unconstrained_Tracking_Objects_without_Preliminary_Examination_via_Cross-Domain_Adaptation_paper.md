The paper title is UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation.
The faculty author of the paper UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation is Bhiksha Raj.
The paper UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation publication year is 2023.
Co-authors of the paper UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation are Pha Nguyen, Kha Gia Quach, J. Gauch, S. Khan, B. Raj, Khoa Luu.
The publication ID of the paper UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation is 1901e811-ee72-4b20-8f7e-de08cd395a10.
The publication name of the paper UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation is arXiv.org.
Publication alternate names of the paper UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation are ArXiv.
The publication issn of the paper UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation is 2331-8422.
The publication url of the paper UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation is https://arxiv.org.
The paper abstract is Multiple Object Tracking (MOT) aims to find bounding boxes and identities of targeted objects in consecutive video frames. While fully-supervised MOT methods have achieved high accuracy on existing datasets, they cannot generalize well on a newly obtained dataset or a new unseen domain. In this work, we first address the MOT problem from the cross-domain point of view, imitating the process of new data acquisition in practice. Then, a new cross-domain MOT adaptation from existing datasets is proposed without any pre-defined human knowledge in understanding and modeling objects. It can also learn and update itself from the target data feedback. The intensive experiments are designed on four challenging settings, including MOTSynth to MOT17, MOT17 to MOT20, MOT17 to VisDrone, and MOT17 to DanceTrack. We then prove the adaptability of the proposed self-supervised learning strategy. The experiments also show superior performance on tracking metrics MOTA and IDF1, compared to fully supervised, unsupervised, and self-supervised state-of-the-art methods.
