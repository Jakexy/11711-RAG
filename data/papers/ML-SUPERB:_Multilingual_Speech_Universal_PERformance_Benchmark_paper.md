The paper title is ML-SUPERB: Multilingual Speech Universal PERformance Benchmark.
The faculty author of the paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark is Shinji Watanabe.
The paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark publication year is 2023.
Co-authors of the paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark are Jiatong Shi, Dan Berrebbi, William Chen, Ho-Lam Chung, En-Pei Hu, Wei Huang, Xuankai Chang, Shang-Wen Li, Abdel-rahman Mohamed, Hung-yi Lee, Shinji Watanabe.
The publication ID of the paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark is af90489e-312f-4514-bea2-bcb399cb8ece.
The publication name of the paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark is Interspeech.
The publication type of the paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark is conference.
Publication alternate names of the paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark are Conf Int Speech Commun Assoc, INTERSPEECH, Conference of the International Speech Communication Association.
The publication issn of the paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark is 2308-457X.
The publication url of the paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark is https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech.
Publication alternate urls of the paper ML-SUPERB: Multilingual Speech Universal PERformance Benchmark are http://www.isca-speech.org/.
The paper abstract is Speech processing Universal PERformance Benchmark (SUPERB) is a leaderboard to benchmark the performance of Self-Supervised Learning (SSL) models on various speech processing tasks. However, SUPERB largely considers English speech in its evaluation. This paper presents multilingual SUPERB (ML-SUPERB), covering 143 languages (ranging from high-resource to endangered), and considering both automatic speech recognition and language identification. Following the concept of SUPERB, ML-SUPERB utilizes frozen SSL features and employs a simple framework for multilingual tasks by learning a shallow downstream model. Similar to the SUPERB benchmark, we find speech SSL models can significantly improve performance compared to FBANK features. Furthermore, we find that multilingual models do not always perform better than their monolingual counterparts. We will release ML-SUPERB as a challenge with organized datasets and reproducible training scripts for future multilingual representation research.
