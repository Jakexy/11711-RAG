The paper title is Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties.
The faculty author of the paper Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties is Maarten Sap.
The paper Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties publication year is 2023.
Co-authors of the paper Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties are Taylor Sorensen, Liwei Jiang, Jena D. Hwang, Sydney Levine, Valentina Pyatkin, Peter West, Nouha Dziri, Ximing Lu, Kavel Rao, Chandra Bhagavatula, Maarten Sap, J. Tasioulas, Yejin Choi.
The publication ID of the paper Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties is 1901e811-ee72-4b20-8f7e-de08cd395a10.
The publication name of the paper Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties is arXiv.org.
Publication alternate names of the paper Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties are ArXiv.
The publication issn of the paper Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties is 2331-8422.
The publication url of the paper Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties is https://arxiv.org.
The paper abstract is Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction. We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented. With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.
