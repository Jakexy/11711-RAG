The paper title is Understanding Masked Autoencoders via Hierarchical Latent Variable Models.
The faculty author of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models is Eric P. Xing.
The paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models publication year is 2023.
Co-authors of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models are Lingjing Kong, Martin Q. Ma, Guan-Hong Chen, E. Xing, Yuejie Chi, Louis-Philippe Morency, Kun Zhang.
The publication ID of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models is 768b87bb-8a18-4d9c-a161-4d483c776bcf.
The publication name of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models is Computer Vision and Pattern Recognition.
The publication type of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models is conference.
Publication alternate names of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models are CVPR, Comput Vis Pattern Recognit.
The publication issn of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models is 1063-6919.
The publication url of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models is https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147.
Publication alternate urls of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models are https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition.
The paper abstract is Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.
