The paper title is From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models.
The faculty author of the paper From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models is Maarten Sap.
The paper From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models publication year is 2023.
Co-authors of the paper From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models are Julia Mendelsohn, Ronan Le Bras, Yejin Choi, Maarten Sap.
The publication ID of the paper From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models is 1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44.
The publication name of the paper From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models is Annual Meeting of the Association for Computational Linguistics.
The publication type of the paper From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models is conference.
Publication alternate names of the paper From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models are Annu Meet Assoc Comput Linguistics, Meeting of the Association for Computational Linguistics, ACL, Meet Assoc Comput Linguistics.
The publication url of the paper From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models is https://www.aclweb.org/anthology/venues/acl/.
The paper abstract is Dogwhistles are coded expressions that simultaneously convey one meaning to a broad audience and a second, often hateful or provocative, meaning to a narrow in-group; they are deployed to evade both political repercussions and algorithmic content moderation. For example, the word “cosmopolitan” in a sentence such as “we need to end the cosmopolitan experiment” can mean “worldly” to many but also secretly mean “Jewish” to a select few. We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians’ speeches. We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3’s performance varies widely across types of dogwhistles and targeted groups. Finally, we show that harmful content containing dogwhistles avoids toxicity detection, highlighting online risks presented by such coded language. This work sheds light on the theoretical and applied importance of dogwhistles in both NLP and computational social science, and provides resources to facilitate future research in modeling dogwhistles and mitigating their online harms.
