The paper title is Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session.
The faculty author of the paper Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session is Bhiksha Raj.
The paper Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session publication year is 2023.
Co-authors of the paper Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session are L. Heller, Benjamin Elizalde, B. Raj, Soham Deshmukh.
The publication ID of the paper Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session is 1901e811-ee72-4b20-8f7e-de08cd395a10.
The publication name of the paper Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session is arXiv.org.
Publication alternate names of the paper Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session are ArXiv.
The publication issn of the paper Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session is 2331-8422.
The publication url of the paper Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session is https://arxiv.org.
The paper abstract is Machine Listening, as usually formalized, attempts to perform a task that is, from our perspective, fundamentally human-performable, and performed by humans. Current automated models of Machine Listening vary from purely data-driven approaches to approaches imitating human systems. In recent years, the most promising approaches have been hybrid in that they have used data-driven approaches informed by models of the perceptual, cognitive, and semantic processes of the human system. Not only does the guidance provided by models of human perception and domain knowledge enable better, and more generalizable Machine Listening, in the converse, the lessons learned from these models may be used to verify or improve our models of human perception themselves. This paper summarizes advances in the development of such hybrid approaches, ranging from Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds. The research described herein was presented in a special session on"Synergy between human and machine approaches to sound/scene recognition and processing"at the 2023 ICASSP meeting.
