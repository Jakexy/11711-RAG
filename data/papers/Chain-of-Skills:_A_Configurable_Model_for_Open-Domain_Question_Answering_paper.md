The paper title is Chain-of-Skills: A Configurable Model for Open-Domain Question Answering.
The faculty author of the paper Chain-of-Skills: A Configurable Model for Open-Domain Question Answering is Eric Nyberg.
The paper Chain-of-Skills: A Configurable Model for Open-Domain Question Answering publication year is 2023.
Co-authors of the paper Chain-of-Skills: A Configurable Model for Open-Domain Question Answering are Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, Jianfeng Gao.
The publication ID of the paper Chain-of-Skills: A Configurable Model for Open-Domain Question Answering is 1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44.
The publication name of the paper Chain-of-Skills: A Configurable Model for Open-Domain Question Answering is Annual Meeting of the Association for Computational Linguistics.
The publication type of the paper Chain-of-Skills: A Configurable Model for Open-Domain Question Answering is conference.
Publication alternate names of the paper Chain-of-Skills: A Configurable Model for Open-Domain Question Answering are Annu Meet Assoc Comput Linguistics, Meeting of the Association for Computational Linguistics, ACL, Meet Assoc Comput Linguistics.
The publication url of the paper Chain-of-Skills: A Configurable Model for Open-Domain Question Answering is https://www.aclweb.org/anthology/venues/acl/.
The paper abstract is The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transfer- ability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.
