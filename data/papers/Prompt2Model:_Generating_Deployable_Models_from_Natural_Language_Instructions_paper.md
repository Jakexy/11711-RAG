The paper title is Prompt2Model: Generating Deployable Models from Natural Language Instructions.
The faculty author of the paper Prompt2Model: Generating Deployable Models from Natural Language Instructions is Graham Neubig.
The paper Prompt2Model: Generating Deployable Models from Natural Language Instructions publication year is 2023.
Co-authors of the paper Prompt2Model: Generating Deployable Models from Natural Language Instructions are Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Sherry Wu, Graham Neubig.
The publication ID of the paper Prompt2Model: Generating Deployable Models from Natural Language Instructions is 41bf9ed3-85b3-4c90-b015-150e31690253.
The publication name of the paper Prompt2Model: Generating Deployable Models from Natural Language Instructions is Conference on Empirical Methods in Natural Language Processing.
The publication type of the paper Prompt2Model: Generating Deployable Models from Natural Language Instructions is conference.
Publication alternate names of the paper Prompt2Model: Generating Deployable Models from Natural Language Instructions are Empir Method Nat Lang Process, Empirical Methods in Natural Language Processing, Conf Empir Method Nat Lang Process, EMNLP.
The publication url of the paper Prompt2Model: Generating Deployable Models from Natural Language Instructions is https://www.aclweb.org/portal/emnlp.
The paper abstract is Large language models (LLMs) enable system builders today to create competent NLP systems through prompting, where they only need to describe the task in natural language and provide a few examples. However, in other ways, LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs. In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment. This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets. Over three tasks, we demonstrate that given the same few-shot prompt as input, Prompt2Model trains models that outperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20% while being up to 700 times smaller. We also show that this data can be used to obtain reliable performance estimates of model performance, enabling model developers to assess model reliability before deployment. Prompt2Model is available open-source at https://github.com/neulab/prompt2model.
