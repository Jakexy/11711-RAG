The paper title is Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation.
The faculty author of the paper Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation is Rita Singh.
The paper Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation publication year is 2023.
Co-authors of the paper Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation are Wayne Zhao, Rita Singh.
The publication ID of the paper Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation is 8270cfe1-3713-4325-a7bd-c6a87eed889e.
The publication name of the paper Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation is Entropy.
The publication type of the paper Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation is journal.
The publication issn of the paper Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation is 1099-4300.
The publication url of the paper Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation is http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-155606.
Publication alternate urls of the paper Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation are http://www.mdpi.com/journal/entropy/, http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-155606, https://www.mdpi.com/journal/entropy.
The paper abstract is During phonation, the vocal folds exhibit a self-sustained oscillatory motion, which is influenced by the physical properties of the speaker’s vocal folds and driven by the balance of bio-mechanical and aerodynamic forces across the glottis. Subtle changes in the speaker’s physical state can affect voice production and alter these oscillatory patterns. Measuring these can be valuable in developing computational tools that analyze voice to infer the speaker’s state. Traditionally, vocal fold oscillations (VFOs) are measured directly using physical devices in clinical settings. In this paper, we propose a novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker-by-speaker basis. The approach, called the ADLES-VFT algorithm, is proposed in the context of a joint model that combines a phonation model (with a glottal flow waveform as the output) and a vocal tract acoustic wave propagation model such that the output of the joint model is an estimated waveform. The ADLES-VFT algorithm is a forward-backward algorithm which minimizes the error between the recorded waveform and the output of this joint model to estimate its parameters. Once estimated, these parameter values are used in conjunction with a phonation model to obtain its solutions. Since the parameters correlate with the physical properties of the vocal folds of the speaker, model solutions obtained using them represent the individualized VFOs for each speaker. The approach is flexible and can be applied to various phonation models. In addition to presenting the methodology, we show how the VFOs can be quantified from a dynamical systems perspective for classification purposes. Mathematical derivations are provided in an appendix for better readability.
