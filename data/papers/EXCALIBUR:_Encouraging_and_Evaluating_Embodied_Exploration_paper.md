The paper title is EXCALIBUR: Encouraging and Evaluating Embodied Exploration.
The faculty author of the paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration is Yonatan Bisk.
The paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration publication year is 2023.
Co-authors of the paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration are Hao Zhu, Raghav Kapoor, So Yeon Min, Winson Han, Jiatai Li, Kaiwen Geng, Graham Neubig, Yonatan Bisk, Aniruddha Kembhavi, Luca Weihs.
The publication ID of the paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration is 768b87bb-8a18-4d9c-a161-4d483c776bcf.
The publication name of the paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration is Computer Vision and Pattern Recognition.
The publication type of the paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration is conference.
Publication alternate names of the paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration are CVPR, Comput Vis Pattern Recognit.
The publication issn of the paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration is 1063-6919.
The publication url of the paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration is https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147.
Publication alternate urls of the paper EXCALIBUR: Encouraging and Evaluating Embodied Exploration are https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition.
The paper abstract is Experience precedes understanding. Humans constantly explore and learn about their environment out of curiosity, gather information, and update their models of the world. On the other hand, machines are either trained to learn passively from static and fixed datasets, or taught to complete specific goal-conditioned tasks. To encourage the development of exploratory interactive agents, we present the EXCALIBUR benchmark. EXCALIBUR allows agents to explore their environment for long durations and then query their understanding of the physical world via inquiries like: “is the small heavy red bowl made from glass?” or “is there a silver spoon heavier than the egg?”. This design encourages agents to perform free-form home exploration without myopia induced by goal conditioning. Once the agents have answered a series of questions, they can renter the scene to refine their knowledge, update their beliefs, and improve their performance on the questions. Our experiments demonstrate the challenges posed by this dataset for the present-day state-of-the-art embodied systems and the headroom afforded to develop new innovative methods. Finally, we present a virtual reality interface that enables humans to seamlessly interact within the simulated world and use it to gather human performance measures. EXCALIBUR affords unique challenges in comparison to presentday benchmarks and represents the next frontier for embodied AI research.
