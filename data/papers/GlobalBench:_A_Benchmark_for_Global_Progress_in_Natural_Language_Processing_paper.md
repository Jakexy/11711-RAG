The paper title is GlobalBench: A Benchmark for Global Progress in Natural Language Processing.
The faculty author of the paper GlobalBench: A Benchmark for Global Progress in Natural Language Processing is Graham Neubig.
The paper GlobalBench: A Benchmark for Global Progress in Natural Language Processing publication year is 2023.
Co-authors of the paper GlobalBench: A Benchmark for Global Progress in Natural Language Processing are Yueqi Song, Catherine Cui, Simran Khanuja, Pengfei Liu, FAHIM FAISAL, Alissa Ostapenko, Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Yulia Tsvetkov, Antonios Anastasopoulos, Graham Neubig.
The publication ID of the paper GlobalBench: A Benchmark for Global Progress in Natural Language Processing is 41bf9ed3-85b3-4c90-b015-150e31690253.
The publication name of the paper GlobalBench: A Benchmark for Global Progress in Natural Language Processing is Conference on Empirical Methods in Natural Language Processing.
The publication type of the paper GlobalBench: A Benchmark for Global Progress in Natural Language Processing is conference.
Publication alternate names of the paper GlobalBench: A Benchmark for Global Progress in Natural Language Processing are Empir Method Nat Lang Process, Empirical Methods in Natural Language Processing, Conf Empir Method Nat Lang Process, EMNLP.
The publication url of the paper GlobalBench: A Benchmark for Global Progress in Natural Language Processing is https://www.aclweb.org/portal/emnlp.
The paper abstract is Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.
