The paper title is I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition.
The faculty author of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition is Shinji Watanabe.
The paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition publication year is 2023.
Co-authors of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition are Yifan Peng, Jaesong Lee, Shinji Watanabe.
The publication ID of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition is 0d6f7fba-7092-46b3-8039-93458dba736b.
The publication name of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition is IEEE International Conference on Acoustics, Speech, and Signal Processing.
The publication type of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition is conference.
Publication alternate names of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition are Int Conf Acoust Speech Signal Process, IEEE Int Conf Acoust Speech Signal Process, ICASSP, International Conference on Acoustics, Speech, and Signal Processing.
The publication url of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition is http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002.
The paper abstract is Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.
