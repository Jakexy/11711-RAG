Faculty: Shinji Watanabe
Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
Abstract: Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.
Year: 2023
Authors: Yifan Peng, Jaesong Lee, Shinji Watanabe
Publication ID: 0d6f7fba-7092-46b3-8039-93458dba736b
Publication Name: IEEE International Conference on Acoustics, Speech, and Signal Processing
Publication Type: conference
Publication Alternate Names: Int Conf Acoust Speech Signal Process, IEEE Int Conf Acoust Speech Signal Process, ICASSP, International Conference on Acoustics, Speech, and Signal Processing
Publication Url: http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002
