The paper title is Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting.
The faculty author of the paper Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting is Graham Neubig.
The paper Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting publication year is 2023.
Co-authors of the paper Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting are Emmy Liu, Aditi Chaudhary, Graham Neubig.
The publication ID of the paper Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting is 41bf9ed3-85b3-4c90-b015-150e31690253.
The publication name of the paper Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting is Conference on Empirical Methods in Natural Language Processing.
The publication type of the paper Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting is conference.
Publication alternate names of the paper Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting are Empir Method Nat Lang Process, Empirical Methods in Natural Language Processing, Conf Empir Method Nat Lang Process, EMNLP.
The publication url of the paper Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting is https://www.aclweb.org/portal/emnlp.
The paper abstract is Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the meanings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic translation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based machine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of ~4k natural sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.
