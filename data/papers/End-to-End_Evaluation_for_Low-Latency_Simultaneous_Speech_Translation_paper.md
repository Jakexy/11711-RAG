The paper title is End-to-End Evaluation for Low-Latency Simultaneous Speech Translation.
The faculty author of the paper End-to-End Evaluation for Low-Latency Simultaneous Speech Translation is Alexander Waibel.
The paper End-to-End Evaluation for Low-Latency Simultaneous Speech Translation publication year is 2023.
Co-authors of the paper End-to-End Evaluation for Low-Latency Simultaneous Speech Translation are Christian Huber, Tu Anh Dinh, Carlos Mullov, Ngoc-Quan Pham, T. Nguyen, Fabian Retkowski, Stefan Constantin, Enes Yavuz Ugan, Danni Liu, Zhaolin Li, Sai Koneru, J. Niehues, A. Waibel.
The publication ID of the paper End-to-End Evaluation for Low-Latency Simultaneous Speech Translation is 41bf9ed3-85b3-4c90-b015-150e31690253.
The publication name of the paper End-to-End Evaluation for Low-Latency Simultaneous Speech Translation is Conference on Empirical Methods in Natural Language Processing.
The publication type of the paper End-to-End Evaluation for Low-Latency Simultaneous Speech Translation is conference.
Publication alternate names of the paper End-to-End Evaluation for Low-Latency Simultaneous Speech Translation are Empir Method Nat Lang Process, Empirical Methods in Natural Language Processing, Conf Empir Method Nat Lang Process, EMNLP.
The publication url of the paper End-to-End Evaluation for Low-Latency Simultaneous Speech Translation is https://www.aclweb.org/portal/emnlp.
The paper abstract is The challenge of low-latency speech translation has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmentation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this framework. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state-of-the-art cascaded as well as end-to-end systems. Finally, the framework allows to automatically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user.
