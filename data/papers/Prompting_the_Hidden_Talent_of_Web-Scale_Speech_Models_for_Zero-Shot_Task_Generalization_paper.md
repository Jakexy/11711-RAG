The paper title is Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization.
The faculty author of the paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization is Shinji Watanabe.
The paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization publication year is 2023.
Co-authors of the paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization are Puyuan Peng, Brian Yan, Shinji Watanabe, David F. Harwath.
The publication ID of the paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization is af90489e-312f-4514-bea2-bcb399cb8ece.
The publication name of the paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization is Interspeech.
The publication type of the paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization is conference.
Publication alternate names of the paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization are Conf Int Speech Commun Assoc, INTERSPEECH, Conference of the International Speech Communication Association.
The publication issn of the paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization is 2308-457X.
The publication url of the paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization is https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech.
Publication alternate urls of the paper Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization are http://www.isca-speech.org/.
The paper abstract is We investigate the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering. We selected three tasks: audio-visual speech recognition (AVSR), code-switched speech recognition (CS-ASR), and speech translation (ST) on unseen language pairs. We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts. Experiments show that compared to the default prompts, our proposed prompts improve performance by 10% to 45% on the three zero-shot tasks, and even outperform SotA supervised models on some datasets. In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space. Code is available at https://github.com/jasonppy/PromptingWhisper
