The paper title is Training on Foveated Images Improves Robustness to Adversarial Attacks.
The faculty author of the paper Training on Foveated Images Improves Robustness to Adversarial Attacks is Bhiksha Raj.
The paper Training on Foveated Images Improves Robustness to Adversarial Attacks publication year is 2023.
Co-authors of the paper Training on Foveated Images Improves Robustness to Adversarial Attacks are Muhammad A Shah, B. Raj.
The publication ID of the paper Training on Foveated Images Improves Robustness to Adversarial Attacks is d9720b90-d60b-48bc-9df8-87a30b9a60dd.
The publication name of the paper Training on Foveated Images Improves Robustness to Adversarial Attacks is Neural Information Processing Systems.
The publication type of the paper Training on Foveated Images Improves Robustness to Adversarial Attacks is conference.
Publication alternate names of the paper Training on Foveated Images Improves Robustness to Adversarial Attacks are Neural Inf Process Syst, NeurIPS, NIPS.
The publication url of the paper Training on Foveated Images Improves Robustness to Adversarial Attacks is http://neurips.cc/.
The paper abstract is Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks -- subtle, perceptually indistinguishable perturbations of inputs that change the response of the model. In the context of vision, we hypothesize that an important contributor to the robustness of human visual perception is constant exposure to low-fidelity visual stimuli in our peripheral vision. To investigate this hypothesis, we develop \RBlur, an image transform that simulates the loss in fidelity of peripheral vision by blurring the image and reducing its color saturation based on the distance from a given fixation point. We show that compared to DNNs trained on the original images, DNNs trained on images transformed by \RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\% higher accuracy on perturbed data.
