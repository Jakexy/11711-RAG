The paper title is Faith and Fate: Limits of Transformers on Compositionality.
The faculty author of the paper Faith and Fate: Limits of Transformers on Compositionality is Sean Welleck.
The paper Faith and Fate: Limits of Transformers on Compositionality publication year is 2023.
Co-authors of the paper Faith and Fate: Limits of Transformers on Compositionality are Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jian, Bill Yuchen Lin, Peter West, Chandra Bhagavatula, Ronan Le Bras, Jena D. Hwang, Soumya Sanyal, S. Welleck, Xiang Ren, Allyson Ettinger, Za√Ød Harchaoui, Yejin Choi.
The publication ID of the paper Faith and Fate: Limits of Transformers on Compositionality is d9720b90-d60b-48bc-9df8-87a30b9a60dd.
The publication name of the paper Faith and Fate: Limits of Transformers on Compositionality is Neural Information Processing Systems.
The publication type of the paper Faith and Fate: Limits of Transformers on Compositionality is conference.
Publication alternate names of the paper Faith and Fate: Limits of Transformers on Compositionality are Neural Inf Process Syst, NeurIPS, NIPS.
The publication url of the paper Faith and Fate: Limits of Transformers on Compositionality is http://neurips.cc/.
The paper abstract is Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify transformer LLMs, we investigate the limits of these models across three representative compositional tasks -- multi-digit multiplication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that transformer LLMs solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem-solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how autoregressive generations' performance can rapidly decay with\,increased\,task\,complexity.
